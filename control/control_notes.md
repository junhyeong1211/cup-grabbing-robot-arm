# 로봇 제어 학습 노트: 로봇에게 생명을 불어넣는 법 

## 1. 시작점: "어떻게 로봇을 움직이지?" 라는 근본적인 질문

어제 `PyBullet`으로 로봇을 가상 세계에 소환하는 데는 성공했지만 그건 그냥 3D 모델에 불과했다. 

> **"어떻게 이 로봇을 내가 원하는 `(X,Y,Z)` 좌표로 팔을 뻗게 할 수 있을까?"**

이 질문에 답하기 위해, 로봇 공학의 가장 근본적인 두 가지 개념인 **순기구학(Forward Kinematics)**과 **역기구학(Inverse Kinematics)**을 파고들었다.

---

## 2. 해답: 순기구학(FK)과 역기구학(IK)

### 2.1. 순기구학 (Forward Kinematics, FK): "관절 각도를 알 때, 손끝은 어디에 있는가?"

* **개념:** 로봇의 각 관절 각도($\theta_1, \theta_2, ...$)가 주어졌을 때, 로봇팔의 End-Effector이 최종적으로 어떤 3D 위치와 방향을 갖게 되는지 계산하는 과정.
* **원리:** 베이스부터 각 관절을 거쳐 손끝까지, 이웃한 좌표계 사이의 관계를 나타내는 **[4x4 변환 행렬(Transformation Matrix)]**(https://goeden.tistory.com/27) 을 순서대로 계속 곱해나가는 단순한 계산 문제다.
    > $T_{base \to hand} = T_{base \to 1} \times T_{1 \to 2} \times \dots \times T_{6 \to hand}$
* **우리 프로젝트에서의 역할:** 주로 결과를 **검증**하는 용도로 사용된다. 예를 들어, 역기구학으로 로봇을 움직인 뒤 `p.getLinkState()` 함수를 호출하여 실제로 손끝이 목표 지점에 도달했는지 확인할 때 쓰인다.

### 2.2. 역기구학 (Inverse Kinematics, IK): "손끝을 특정 위치로 보내려면, 관절 각도는 몇 도여야 하는가?"

* **개념:** 순기구학의 정반대 문제. 순기구학보다 훨씬 복잡하다. 우리가 원하는 손끝의 목표 3D 위치 `(X,Y,Z)`가 주어졌을 때, 그 위치를 만들기 위한 각 관절의 각도($\theta_1, \theta_2, ...$)를 역으로 계산하는 과정이다.
* **어려움:** 수많은 삼각함수가 얽힌 복잡한 비선형 연립 방정식을 푸는 것과 같다. 이 방정식은 해가 없거나(닿지 않는 거리), 하나이거나, 여러 개일 수 있다(같은 손끝 위치를 만드는 여러 팔 자세).
* **우리 프로젝트에서의 역할:** **이것이 바로 로봇 제어의 핵심이다.** 다행히도 우리는 이 어려운 수학을 직접 풀 필요가 없다. 그건 뒤에서 설명하겠다.

---

## 3. PyBullet 실전: 핵심 함수 톺아보기

PyBullet은 역기구학이라는 어려운 문제를 해결해준다. 오늘 실습은 이 계산기를 사용하는 방법을 배운 것이다.

### 3.1. `p.calculateInverseKinematics()`: 역기구학 전문 계산기

* **역할:** "이 로봇의, 이쪽 끝을, 저 3D 좌표로 보내려면, 각 관절 각도는 몇이 되어야 해?" 라는 질문에 대한 답을 순식간에 계산해 준다.
* **입력:** `robotId`, `endEffectorIndex`, `targetPosition`
* **출력:** `target_joint_angles` (각 관절이 도달해야 할 목표 각도 리스트)

### 3.2. `p.setJointMotorControlArray()`: 로봇 관절의 지휘자

* **역할:** 계산된 목표 각도를 실제 로봇의 각 관절 모터에 '목표 지점'으로 설정해 주는 명령이다.
* **핵심 파라미터:**
    * `controlMode=p.POSITION_CONTROL`: 모터 제어 방식을 '위치 제어'로 설정. 즉, "어떤 힘이 들든, 지정된 각도에 도달하고 그 위치를 유지해라!"는 의미.
    * `targetPositions=target_joint_angles`: 각 모터가 도달해야 할 구체적인 각도 값.

### 3.3. `p.stepSimulation()`: 가상 세계의 시간을 흐르게 하는 신

* **역할:** 위에서 내린 명령(`set...Control...`)은 '목표'를 설정한 것일 뿐, 로봇이 실제로 움직이지는 않는다. `p.stepSimulation()`을 호출해야 비로소 가상 세계의 시간이 한 스텝(기본 1/240초) 흐르며, 모터가 목표를 향해 움직이는 물리 현상이 계산된다. `for` 루프를 통해 이 함수를 반복 호출하면, 로봇이 움직이는 애니메이션이 만들어진다.

---

## 4. "End-to-End..." 논문에서 얻은 영감

오늘 배운 역기구학(IK) 방식은 목표 지점에 대한 '정답' 관절 각도를 수학적으로 계산하는 **전통적이고 정교한 제어 방식**이다.

하지만 "End-to-End Training of Deep Visuomotor Policies" 논문은 전혀 다른 접근법을 제시한다.

> 카메라 이미지(Vision)를 입력받아, 중간의 복잡한 IK 계산 없이, 곧바로 모터 제어 명령(Motor)을 출력하는 **하나의 거대한 신경망**을 만들 수 있다는 것이다.

이것은 수많은 '경험(성공과 실패)'을 통해 정답을 계산하는 대신, 정답에 가까운 행동을 '근사'하도록 학습하는 딥러닝 방식이다. 우리 프로젝트의 최종 목표인 **강화학습은 바로 이 후자의 접근법**에 속한다. 오늘 배운 IK는 그 최종 목표와 비교하며 이해할 수 있는 훌륭한 '기준점'이 되어주었다.

---

## 5. 결론 및 다음 질문 (To-Do)

* **오늘의 결론:** 로봇 제어의 가장 기본적인 '뼈대'를 세웠다. 역기구학이라는 강력한 도구를 이용해, 추상적인 3D 목표 지점을 실제 로봇의 관절 움직임으로 변환하는 데 성공했다.
* **다음 질문:**
    * 지금은 목표 지점으로 순간 이동하듯 움직인다. 시작점부터 목표점까지 부드러운 '경로'를 따라 움직이게 하려면 어떻게 해야 할까? (Motion Planning)
    * 만약 로봇팔과 컵 사이에 장애물이 있다면 어떻게 피할 수 있을까?
    * 오늘 배운 IK 기반 제어에서, 어떻게 강화학습(RL) 기반 제어로 전환할 수 있을까?

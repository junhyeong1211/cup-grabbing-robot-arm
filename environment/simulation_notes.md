## 1. PyBullet: 로봇을 위한 가상 놀이터

PyBullet은 강화학습의 'Environment'을 만드는 데 사용되는 핵심적인 **오픈소스 물리 시뮬레이터**입니다. 로봇이 현실 세계에서 겪을 수많은 시행착오를 컴퓨터 안에서 빠르고 안전하게 경험할 수 있는 '가상 환경'을 제공합니다.

### 1.1. PyBullet의 역할: 3D 세상의 '신God'

PyBullet은 가상 세계의 모든 규칙을 관장합니다.

* **물리 엔진:** "사과가 떨어진다"와 같은 **중력**(`p.setGravity`), 물체끼리 부딪혔을 때의 **충돌(Collision)**, 바닥을 미끄러질 때의 **마찰(Friction)** 등 현실의 물리 법칙을 코드로 내린 명령에 따라 계산합니다. 이 계산 덕분에 로봇의 움직임이 현실과 가깝게 표현됩니다.
* **3D 세상 구현:** 로봇, 사물, 지형 등 3D 모델을 불러와 3차원 공간에 배치합니다. 이 공간은 **데카르트 좌표계(Cartesian Coordinate System)**로 정의되며, 모든 물체는 고유한 `(X, Y, Z)` 좌표를 가집니다. `p.loadURDF("plane.urdf")`는 Z=0 위치에 무한한 바닥 평면을 생성하는 역할을 합니다.

### 1.2. Colab 환경에서의 특징: 왜 `p.DIRECT`를 사용하는가?

Colab은 우리가 웹 브라우저를 통해 접속하는 모니터가 없는 원격 서버입니다.

* `p.connect(p.GUI)`: 이 모드는 별도의 그래픽 창을 띄워 시뮬레이션을 보여주는 방식입니다. 하지만 Colab 서버에는 우리가 볼 수 있는 GUI가 없기 때문에 이 모드를 사용하면 오류가 발생합니다.
* `p.connect(p.DIRECT)`: 이 모드는 그래픽 창 없이 **오직 계산만** 백그라운드에서 수행합니다. AI 학습 시 수백만 번의 시뮬레이션을 반복할 때 화면을 그리는 과정을 생략하기 때문에 **압도적으로 빠른 속도**를 제공합니다.

> **Q: 그럼 Colab에서 화면을 볼 수 없나요?**
> * A: `p.getCameraImage()` 함수를 사용합니다. 이것은 시뮬레이션 세상 속 특정 `(X,Y,Z)` 좌표에 가상의 카메라를 설치하고, 그 카메라가 바라보는 장면을 **'사진(RGB 이미지)'**으로 찍어 우리에게 보여주는 방식입니다.
예시코드는 다음과 같습니다.
```python
# 카메라 위치, 바라보는 지점, 카메라 상단 방향 벡터를 설정
viewMatrix = p.computeViewMatrix(
    cameraEyePosition=[1, 1, 1],      # 카메라 위치 (x,y,z)
    cameraTargetPosition=[0, 0, 0.7], # 카메라가 바라볼 지점
    cameraUpVector=[0, 0, 1]          # 카메라의 위쪽 방향
)
```
---

## 2. URDF: 로봇의 디지털 설계도

URDF(Unified Robot Description Format)는 로봇의 구조를 3D 공간상에서 수학적으로 정의하는 **표준 XML 파일 형식**입니다.
> **XML이란?** 간단하게 말하면 주로 웹에서 데이터를 전송하기 위해 미리 약속해둔 방식으로 만들어진 문서를 말합니다.

* **역할:** 로봇의 '몸'을 구성하는 모든 정보를 담고 있습니다.
    * **Links (뼈대):** 로봇의 각 부분(팔, 다리 등)의 모양, 크기, 질량, 관성 등 물리적 특성을 정의합니다.
    * **Joints (관절):** 각 링크가 어떤 **좌표**를 기준으로 어떤 **축**을 중심으로 회전하거나 미끄러지는지 수학적으로 정의합니다.
* **PyBullet과의 관계:** `p.loadURDF()` 함수는 이 URDF 설계도를 읽고 그 내용대로 3D 공간에 링크와 관절들을 조립하여 로봇을 '소환'하는 역할을 합니다.

---

## 3. "Domain Randomization" 논문 인사이트

* **핵심 문제 (Reality Gap):** 시뮬레이션은 완벽할 수 없습니다. 시뮬레이터의 물리 값(마찰 계수 등)과 실제 세상의 값은 미세하게 다르며, 센서 노이즈, 조명 변화 등 예측 불가능한 변수가 현실에는 존재합니다. 이 차이 때문에 시뮬레이션에서 100점짜리 AI도 실제 환경에서는 50점짜리 성능을 낼 수 있습니다.
* **핵심 아이디어 (역발상):**
    > "시뮬레이션을 현실과 **똑같이** 만들려는 노력을 포기하고, 차라리 현실에서 나타날 수 있는 **모든 가능성을 포함하는 수많은 가짜 환경**을 만들자!"
* **결론:** AI가 훈련 중에 다양한 색깔, 조명, 질감, 물리 값에 무작위로 노출되면, 특정 환경에 과적합되지 않고 더 **강인한 일반화 능력**을 갖게 됩니다. 이를 통해 처음 보는 실제 환경에 대한 적응력이 높아집니다.
* 이 아이디어에 대한 더 자세한 내용은 ["Domain Randomization" 논문](https://arxiv.org/pdf/1703.06907)에서 확인할 수 있습니다.
---

## 4. To-Do - 추가적으로 궁금한 점

* 내가 직접 만든 3D 모델(CAD 파일 등)을 URDF로 변환해서 PyBullet에 불러올 수는 없을까?
* 로봇팔의 각 관절을 내가 원하는 정확한 각도로 움직이려면 어떤 함수를 사용해야 할까? 
